{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1611caed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports.\n",
    "import pandas as pd\n",
    "from path import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a1f3b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>start station id</th>\n",
       "      <th>start station latitude</th>\n",
       "      <th>start station longitude</th>\n",
       "      <th>end station id</th>\n",
       "      <th>end station latitude</th>\n",
       "      <th>end station longitude</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>usertype</th>\n",
       "      <th>birth year</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>538</td>\n",
       "      <td>2016-05-01 00:00:03</td>\n",
       "      <td>2016-05-01 00:09:02</td>\n",
       "      <td>536</td>\n",
       "      <td>40.741444</td>\n",
       "      <td>-73.975361</td>\n",
       "      <td>497</td>\n",
       "      <td>40.737050</td>\n",
       "      <td>-73.990093</td>\n",
       "      <td>23097</td>\n",
       "      <td>1</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>224</td>\n",
       "      <td>2016-05-01 00:00:04</td>\n",
       "      <td>2016-05-01 00:03:49</td>\n",
       "      <td>361</td>\n",
       "      <td>40.716059</td>\n",
       "      <td>-73.991908</td>\n",
       "      <td>340</td>\n",
       "      <td>40.712690</td>\n",
       "      <td>-73.987763</td>\n",
       "      <td>23631</td>\n",
       "      <td>1</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>328</td>\n",
       "      <td>2016-05-01 00:00:14</td>\n",
       "      <td>2016-05-01 00:05:43</td>\n",
       "      <td>301</td>\n",
       "      <td>40.722174</td>\n",
       "      <td>-73.983688</td>\n",
       "      <td>311</td>\n",
       "      <td>40.717227</td>\n",
       "      <td>-73.988021</td>\n",
       "      <td>23049</td>\n",
       "      <td>1</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>753</td>\n",
       "      <td>2016-05-01 00:00:26</td>\n",
       "      <td>2016-05-01 00:13:00</td>\n",
       "      <td>492</td>\n",
       "      <td>40.750200</td>\n",
       "      <td>-73.990931</td>\n",
       "      <td>228</td>\n",
       "      <td>40.754601</td>\n",
       "      <td>-73.971879</td>\n",
       "      <td>16437</td>\n",
       "      <td>1</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>511</td>\n",
       "      <td>2016-05-01 00:00:33</td>\n",
       "      <td>2016-05-01 00:09:05</td>\n",
       "      <td>445</td>\n",
       "      <td>40.727408</td>\n",
       "      <td>-73.981420</td>\n",
       "      <td>537</td>\n",
       "      <td>40.740259</td>\n",
       "      <td>-73.984092</td>\n",
       "      <td>20592</td>\n",
       "      <td>1</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tripduration            starttime             stoptime  start station id  \\\n",
       "0           538  2016-05-01 00:00:03  2016-05-01 00:09:02               536   \n",
       "1           224  2016-05-01 00:00:04  2016-05-01 00:03:49               361   \n",
       "2           328  2016-05-01 00:00:14  2016-05-01 00:05:43               301   \n",
       "3           753  2016-05-01 00:00:26  2016-05-01 00:13:00               492   \n",
       "4           511  2016-05-01 00:00:33  2016-05-01 00:09:05               445   \n",
       "\n",
       "   start station latitude  start station longitude  end station id  \\\n",
       "0               40.741444               -73.975361             497   \n",
       "1               40.716059               -73.991908             340   \n",
       "2               40.722174               -73.983688             311   \n",
       "3               40.750200               -73.990931             228   \n",
       "4               40.727408               -73.981420             537   \n",
       "\n",
       "   end station latitude  end station longitude  bikeid  usertype  birth year  \\\n",
       "0             40.737050             -73.990093   23097         1      1986.0   \n",
       "1             40.712690             -73.987763   23631         1      1977.0   \n",
       "2             40.717227             -73.988021   23049         1      1980.0   \n",
       "3             40.754601             -73.971879   16437         1      1981.0   \n",
       "4             40.740259             -73.984092   20592         1      1991.0   \n",
       "\n",
       "   gender  \n",
       "0       2  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "file_path = Path(\"Resources/allmay_cleaned.csv\")\n",
    "allmay_df = pd.read_csv(file_path)\n",
    "allmay_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "765e15e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tripduration                 int64\n",
       "starttime                   object\n",
       "stoptime                    object\n",
       "start station id             int64\n",
       "start station latitude     float64\n",
       "start station longitude    float64\n",
       "end station id               int64\n",
       "end station latitude       float64\n",
       "end station longitude      float64\n",
       "bikeid                       int64\n",
       "usertype                     int64\n",
       "birth year                 float64\n",
       "gender                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allmay_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a744959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Convert date columns to datetime from object\n",
    "allmay_df['starttime'] = pd.to_datetime(allmay_df['starttime'])\n",
    "allmay_df['stoptime'] = pd.to_datetime(allmay_df['stoptime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2df53fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tripduration                        int64\n",
       "starttime                  datetime64[ns]\n",
       "stoptime                   datetime64[ns]\n",
       "start station id                    int64\n",
       "start station latitude            float64\n",
       "start station longitude           float64\n",
       "end station id                      int64\n",
       "end station latitude              float64\n",
       "end station longitude             float64\n",
       "bikeid                              int64\n",
       "usertype                            int64\n",
       "birth year                        float64\n",
       "gender                              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allmay_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b77b7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>start station id</th>\n",
       "      <th>start station latitude</th>\n",
       "      <th>start station longitude</th>\n",
       "      <th>end station id</th>\n",
       "      <th>end station latitude</th>\n",
       "      <th>end station longitude</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>usertype</th>\n",
       "      <th>birth year</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>538</td>\n",
       "      <td>536</td>\n",
       "      <td>40.741444</td>\n",
       "      <td>-73.975361</td>\n",
       "      <td>497</td>\n",
       "      <td>40.737050</td>\n",
       "      <td>-73.990093</td>\n",
       "      <td>23097</td>\n",
       "      <td>1</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>224</td>\n",
       "      <td>361</td>\n",
       "      <td>40.716059</td>\n",
       "      <td>-73.991908</td>\n",
       "      <td>340</td>\n",
       "      <td>40.712690</td>\n",
       "      <td>-73.987763</td>\n",
       "      <td>23631</td>\n",
       "      <td>1</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>328</td>\n",
       "      <td>301</td>\n",
       "      <td>40.722174</td>\n",
       "      <td>-73.983688</td>\n",
       "      <td>311</td>\n",
       "      <td>40.717227</td>\n",
       "      <td>-73.988021</td>\n",
       "      <td>23049</td>\n",
       "      <td>1</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>753</td>\n",
       "      <td>492</td>\n",
       "      <td>40.750200</td>\n",
       "      <td>-73.990931</td>\n",
       "      <td>228</td>\n",
       "      <td>40.754601</td>\n",
       "      <td>-73.971879</td>\n",
       "      <td>16437</td>\n",
       "      <td>1</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>511</td>\n",
       "      <td>445</td>\n",
       "      <td>40.727408</td>\n",
       "      <td>-73.981420</td>\n",
       "      <td>537</td>\n",
       "      <td>40.740259</td>\n",
       "      <td>-73.984092</td>\n",
       "      <td>20592</td>\n",
       "      <td>1</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tripduration  start station id  start station latitude  \\\n",
       "0           538               536               40.741444   \n",
       "1           224               361               40.716059   \n",
       "2           328               301               40.722174   \n",
       "3           753               492               40.750200   \n",
       "4           511               445               40.727408   \n",
       "\n",
       "   start station longitude  end station id  end station latitude  \\\n",
       "0               -73.975361             497             40.737050   \n",
       "1               -73.991908             340             40.712690   \n",
       "2               -73.983688             311             40.717227   \n",
       "3               -73.990931             228             40.754601   \n",
       "4               -73.981420             537             40.740259   \n",
       "\n",
       "   end station longitude  bikeid  usertype  birth year  gender  \n",
       "0             -73.990093   23097         1      1986.0       2  \n",
       "1             -73.987763   23631         1      1977.0       1  \n",
       "2             -73.988021   23049         1      1980.0       1  \n",
       "3             -73.971879   16437         1      1981.0       1  \n",
       "4             -73.984092   20592         1      1991.0       1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the datetime columns\n",
    "allmay_df.drop(columns=[\"starttime\", \"stoptime\"], inplace=True)\n",
    "allmay_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e773f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove usertype target from features data\n",
    "y = allmay_df['usertype'].ravel()\n",
    "X = allmay_df.drop(columns=[\"usertype\"])\n",
    "\n",
    "# Split training/test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50c98282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Random forest predictive accuracy: 0.957\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier.\n",
    "rf_model = RandomForestClassifier(n_estimators=128, random_state=78)\n",
    "\n",
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf_model.predict(X_test)\n",
    "print(f\" Random forest predictive accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7805d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c9da4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b03b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 =  24\n",
    "hidden_nodes_layer2 = 12\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed49491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importance in the Random Forest model.\n",
    "importances = rf_model.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82161e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can sort the features by their importance.\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcbc17b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc57497d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eb3e333",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14615c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "814c4299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Logistic regression model accuracy: 0.907\n"
     ]
    }
   ],
   "source": [
    "# Define the logistic regression model\n",
    "log_classifier = LogisticRegression(solver=\"lbfgs\",max_iter=200)\n",
    "\n",
    "# Train the model\n",
    "log_classifier.fit(X_train,y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = log_classifier.predict(X_test)\n",
    "print(f\" Logistic regression model accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc714df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "143805/143805 [==============================] - 95s 660us/step - loss: 0.1622 - accuracy: 0.9492\n",
      "Epoch 2/50\n",
      "143805/143805 [==============================] - 94s 656us/step - loss: 0.1545 - accuracy: 0.9506\n",
      "Epoch 3/50\n",
      "143805/143805 [==============================] - 92s 639us/step - loss: 0.1535 - accuracy: 0.9508\n",
      "Epoch 4/50\n",
      "143805/143805 [==============================] - 91s 631us/step - loss: 0.1531 - accuracy: 0.9509\n",
      "Epoch 5/50\n",
      "143805/143805 [==============================] - 90s 628us/step - loss: 0.1521 - accuracy: 0.9511\n",
      "Epoch 6/50\n",
      "143805/143805 [==============================] - 94s 655us/step - loss: 0.1519 - accuracy: 0.9512\n",
      "Epoch 7/50\n",
      "143805/143805 [==============================] - 93s 647us/step - loss: 0.1518 - accuracy: 0.9512\n",
      "Epoch 8/50\n",
      "134493/143805 [===========================>..] - ETA: 6s - loss: 0.1518 - accuracy: 0.9512"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-dcd1f5649d9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mfit_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Evaluate the model using the test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3024\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1961\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the basic neural network model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=16, activation=\"relu\", input_dim=10))\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=50)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5fbc21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4656d4ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
